import pandas as pd
import numpy as np
import joblib
import argparse
import sys
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
import urllib.parse


def create_db_engine():
    """–°–æ–∑–¥–∞–µ—Ç –¥–≤–∏–∂–æ–∫ SQLAlchemy —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
    dotenv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
    if os.path.exists(dotenv_path):
        load_dotenv(dotenv_path)
    else:
        print(f"‚ùå –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –Ω–µ –Ω–∞–π–¥–µ–Ω .env —Ñ–∞–π–ª –ø–æ –ø—É—Ç–∏ {dotenv_path}")

    db_user = os.getenv('DB_USER')
    db_password = os.getenv('DB_PASSWORD')
    db_host = os.getenv('DB_HOST')
    db_name = os.getenv('DB_NAME')
    db_port = os.getenv('DB_PORT', '3306')

    if not all([db_user, db_password, db_host, db_name]):
        print("‚ùå –û—à–∏–±–∫–∞: –û–¥–Ω–∞ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ .env —Ñ–∞–π–ª–µ.")
        print("   –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ DB_USER, DB_PASSWORD, DB_HOST, DB_NAME.")
        sys.exit(1)
    try:
        encoded_password = urllib.parse.quote_plus(db_password)
        db_url = f"mysql+pymysql://{db_user}:{encoded_password}@{db_host}:{db_port}/{db_name}"
        return create_engine(db_url)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–≤–∏–∂–∫–∞ SQLAlchemy: {e}", file=sys.stderr)
        sys.exit(1)


def get_single_signal_data(engine, signal_id: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞."""
    # –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –ø–æ–ª—è –∏–∑ –æ–±–µ–∏—Ö —Ç–∞–±–ª–∏—Ü –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ ID
    query = text("""
                 SELECT s.*,
                        e.id as enriched_id,
                        e.oi_usdt_average,
                        e.oi_usdt_current,
                        e.oi_usdt_yesterday,
                        e.oi_usdt_change_current_to_yesterday,
                        e.oi_usdt_change_current_to_average,
                        e.oi_source_usdt,
                        e.spot_volume_usdt_average,
                        e.spot_volume_usdt_current,
                        e.spot_volume_usdt_yesterday,
                        e.spot_volume_usdt_change_current_to_yesterday,
                        e.spot_volume_usdt_change_current_to_average,
                        e.spot_volume_source_usdt,
                        e.spot_volume_btc_average,
                        e.spot_volume_btc_current,
                        e.spot_volume_btc_yesterday,
                        e.spot_volume_btc_change_current_to_yesterday,
                        e.spot_volume_btc_change_current_to_average,
                        e.spot_volume_source_btc,
                        e.spot_price_usdt_average,
                        e.spot_price_usdt_current,
                        e.spot_price_usdt_yesterday,
                        e.spot_price_usdt_change_1h,
                        e.spot_price_usdt_change_24h,
                        e.spot_price_usdt_change_7d,
                        e.spot_price_usdt_change_30d,
                        e.spot_price_source_usdt,
                        e.cmc_price_min_1h,
                        e.cmc_price_max_1h,
                        e.cmc_price_min_24h,
                        e.cmc_price_max_24h,
                        e.cmc_price_min_7d,
                        e.cmc_price_max_7d,
                        e.cmc_price_min_30d,
                        e.cmc_price_max_30d,
                        e.cmc_percent_change_1d,
                        e.cmc_percent_change_7d,
                        e.cmc_percent_change_30d
                 FROM signals_10min s
                          LEFT JOIN signals_10min_enriched e ON s.id = e.signal_id
                 WHERE s.id = :signal_id;
                 """)
    df = pd.read_sql(query, engine, params={"signal_id": signal_id})
    if df.empty:
        return None
    df.rename(columns={'id': 'signal_id'}, inplace=True)
    return df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∫—Ä–∏–ø—Ç–æ-—Å–∏–≥–Ω–∞–ª–∞.")
    parser.add_argument('--signal_id', type=int, required=True, help='ID —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.')
    args = parser.parse_args()

    print("–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–≤–µ–π–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π...")
    try:
        rf_pipeline = joblib.load('rf_pipeline.joblib')
        xgb_pipeline = joblib.load('xgb_pipeline.joblib')
        lgbm_pipeline = joblib.load('lgbm_pipeline.joblib')
        print("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    except FileNotFoundError as e:
        print(
            f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {e.filename}. \n   –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç train_all_models.py –¥–ª—è –∏—Ö —Å–æ–∑–¥–∞–Ω–∏—è.")
        sys.exit(1)

    engine = create_db_engine()
    print(f"\n–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–≥–Ω–∞–ª–∞ ID: {args.signal_id}...")
    signal_df = get_single_signal_data(engine, args.signal_id)

    if signal_df is None:
        print(f"‚ùå –°–∏–≥–Ω–∞–ª —Å ID {args.signal_id} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    else:
        print("–î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")

        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—ã—Ä–æ–π DataFrame.
        # –í—Å—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω–≤–µ–π–µ—Ä–æ–≤.
        X_predict = signal_df

        # –ü–æ–ª—É—á–∞–µ–º "–≥–æ–ª–æ—Å–∞" –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        rf_vote = rf_pipeline.predict(X_predict)[0]
        rf_proba = rf_pipeline.predict_proba(X_predict)[0][1]

        xgb_vote = xgb_pipeline.predict(X_predict)[0]
        xgb_proba = xgb_pipeline.predict_proba(X_predict)[0][1]

        # –î–ª—è LightGBM –º—ã –¥–æ–ª–∂–Ω—ã –≤—Ä—É—á–Ω—É—é –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        X_predict_lgbm = X_predict.copy()
        categorical_features = X_predict_lgbm.select_dtypes(include=['object']).columns
        for col in categorical_features:
            X_predict_lgbm[col] = X_predict_lgbm[col].astype('category')

        lgbm_vote = lgbm_pipeline.predict(X_predict_lgbm)[0]
        lgbm_proba = lgbm_pipeline.predict_proba(X_predict_lgbm)[0][1]

        votes = [rf_vote, xgb_vote, lgbm_vote]
        successful_votes = sum(votes)
        avg_proba = np.mean([rf_proba, xgb_proba, lgbm_proba])

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print("\n" + "=" * 60)
        print(f"–†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–°–ê–ú–ë–õ–ï–í–û–ì–û –ê–ù–ê–õ–ò–ó–ê –î–õ–Ø –°–ò–ì–ù–ê–õ–ê #{args.signal_id} ({signal_df['symbol'].iloc[0]})")
        print("=" * 60)
        print(f"  - –ú–Ω–µ–Ω–∏–µ Random Forest: {'–£—Å–ø–µ—Ö' if rf_vote else '–ü—Ä–æ–≤–∞–ª'} (–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {rf_proba:.1%})")
        print(f"  - –ú–Ω–µ–Ω–∏–µ XGBoost:       {'–£—Å–ø–µ—Ö' if xgb_vote else '–ü—Ä–æ–≤–∞–ª'} (–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {xgb_proba:.1%})")
        print(f"  - –ú–Ω–µ–Ω–∏–µ LightGBM:      {'–£—Å–ø–µ—Ö' if lgbm_vote else '–ü—Ä–æ–≤–∞–ª'} (–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {lgbm_proba:.1%})")
        print("-" * 60)
        print(f"–ò–¢–û–ì–û–í–ê–Ø –°–†–ï–î–ù–Ø–Ø –í–ï–†–û–Ø–¢–ù–û–°–¢–¨ –£–°–ü–ï–•–ê: {avg_proba:.2%}")

        if successful_votes == 3:
            print("\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: üî• –í–•–û–î–ò–¢–¨ (–í—Å–µ –º–æ–¥–µ–ª–∏ —Å–æ–≥–ª–∞—Å–Ω—ã, –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
        elif successful_votes == 2:
            print("\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: ü§î –†–ê–°–°–ú–û–¢–†–ï–¢–¨ (–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –ó–ê, —Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
        else:
            print("\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: ‚õîÔ∏è –ü–†–û–ü–£–°–¢–ò–¢–¨ (–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –ü–†–û–¢–ò–í, –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
        print("=" * 60)

